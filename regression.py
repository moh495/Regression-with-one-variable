# -*- coding: utf-8 -*-
"""Regression

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1jXVlvFOsiCmqlbQDfQB4tAi-cs4y5hxX
"""

# importing Pandas and Numpy and Datasets
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn import datasets 
import seaborn as sns

from google.colab import files
uploaded = files.upload()

import io

data=pd.read_csv(io.BytesIO(uploaded['himi.csv']))

data.head(11)

data.describe()

data.shape

"""# **Data Rescaling**"""

data = (data - data.mean())/data.std()
print("data after normalization = \n " , data.head(11))

from IPython.display import clear_output
data.plot(kind='scatter' , x = 'YearsExperience' , y = 'Salary' , figsize=(7,8) , color=(1.0,0.2,0.3))
plt.title(f"data")
plt.style.use('ggplot')
ax = plt.axes()
plt.show()

"""## **Add ones column**"""

data.insert(0 , 'Ones' , 1)
print(data.head(10))

cols = data.shape[1]
X = data.iloc[ : , 0 : cols-1]
y = data.iloc[: , cols-1 : cols]
print('X data = \n' , X.head(6))
print('y data = \n' , y.head(6))

"""## **convert from data frames to numpy matrices**"""

X = np.matrix(X.values)
y = np.matrix(y.values)
theta = np.matrix(np.array([0,0]))

"""## Cost Function"""

def computeCost(X , y , theta):
  z = np.power(((X * theta.T) - y), 2)
  print('z \n', z)
  print('m' , len(X))
  return np.sum(z) / (2 * len(X))


print('computeCost(X , y , theta) = ' , computeCost(X , y , theta))

"""## **GD Function**"""

def gradientDescent(X, y, theta, alpha, iters):
  temp = np.matrix(np.zeros(theta.shape))
  parameters = int(theta.ravel().shape[1])
  cost = np.zeros(iters)

  for i in range(iters):
    error = (X * theta.T) - y

    for j in range(parameters):
      term = np.multiply(error , X[: , j])
      temp[0,j] = theta[0,j] - ((alpha / len(X)) * np.sum(term))

    theta = temp
    cost[i] = computeCost(X , y , theta)

  return theta , cost

#intialize variables for learning rate and iterations
alpha = 0.01
iters = 1400
g, cost = gradientDescent(X , y , theta , alpha , iters)
print('g = ' , g)
print('cost' , cost[0:50])
print('computeCost = ' , computeCost(X, y , theta))

"""# get best fit **line**"""

x = np.linspace(data.YearsExperience.min() , data.YearsExperience.max() , 100)
f = g[0, 0] + (g[0, 1] * x)
print('f \n' , f)

"""## **draw the line**"""

fig, ax = plt.subplots(figsize=(10,9))
ax.plot(x, f ,'r', label='Prediction')
ax.scatter(data.YearsExperience, data.Salary , label='Training data' , color='g')
_ = plt.legend(loc='best')
ax.legend(loc=2)
ax.set_xlabel('YearsExperience')
ax.set_ylabel('Salary')
ax.set_title('Predicted Salary vs. YearsExperience')

"""## **Draw error graph**"""

fig , ax = plt.subplots(figsize=(10,8))
ax.plot(np.arange(iters) , cost , (1.0,0.2,0.3))
ax.set_xlabel('iterations')
ax.set_ylabel('Cost')
ax.set_title('Error vs . Training Epoch')